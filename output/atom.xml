<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://raphael95.github.io/output</id>
    <title>blog</title>
    <updated>2019-05-30T10:12:22.205Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://raphael95.github.io/output"/>
    <link rel="self" href="https://raphael95.github.io/output/atom.xml"/>
    <subtitle>Ê∏©ÊïÖËÄåÁü•Êñ∞</subtitle>
    <logo>https://raphael95.github.io/output/images/avatar.png</logo>
    <icon>https://raphael95.github.io/output/favicon.ico</icon>
    <rights>All rights reserved 2019, blog</rights>
    <entry>
        <title type="html"><![CDATA[Pattern  Search]]></title>
        <id>https://raphael95.github.io/output/post/pattern-search</id>
        <link href="https://raphael95.github.io/output/post/pattern-search">
        </link>
        <updated>2019-05-30T10:11:05.000Z</updated>
        <summary type="html"><![CDATA[<p>üìùüìì record pattern search algorithms and introduce two solutions</p>
]]></summary>
        <content type="html"><![CDATA[<p>üìùüìì record pattern search algorithms and introduce two solutions</p>
<!-- more -->
<h2 id="introduction">Introduction</h2>
<p>Actually, pattern searching is an important problem in computer sciemce. When we do search for a string in nptepad/word file or browser or database, pattern searching algorithms are used to show the search results. The essence is the problem of finding occurrences of pattern string within another string or body of text, there are many different algorithms for efficient searching.</p>
<h3 id="1-brute-force">1. brute force</h3>
<blockquote>
<p>time complexity: O(N * M)
N is the len of text string, M is the len of pattern string
such as : target = &quot;ABABDABACDABABCABAB&quot;, pattern = &quot;ABABCABAB&quot;</p>
</blockquote>
<p>pseudocode in C:</p>
<pre><code>void pattern_search(char *t, char *p){
	int len_t = strlen(t);
	int len_p = strlen(p);
	bool found;
	for(int i = 0; i &lt; len_t - len_p; i ++){
		found = true;
		for(int j = i; j &lt; i + len_p; j ++){
			if(t[j] != p[j - i]){
				found = false;
				break;
			}
		}
		if(found)
			return i;
	}
	return -1;
}
</code></pre>
<h3 id="2-knuth-morris-pratt-algorithm">2. Knuth-Morris-Pratt Algorithm</h3>
<blockquote>
<p>time complexity: is O(N + M)</p>
</blockquote>
<p>the naive pattern searching/brute force algorithms doesn't work well in cases where we see many matching characters followed any mismatching character.</p>
<p>The KMP matching algorithm uses degenerating property(pattern having same sub-patterns more than once in the pattern)of the pattern and improves the worst case complexity to O(N).The basic idea behind KMP's algorithms is : whenever we detect a mismatch(after some matches), we already know some of the characters in the text of the next window. We take advantage of this information to avoid matching the repeated characters we have known. Here, we need an auxiliary array named next to store the amount of longest common prefix and suffix.</p>
<p>pseudocode in CÔºö</p>
<pre><code>void prefix(char *p, int *next){
	int len_p = strlen(p);
	for(int i = 1; i &lt; len_p; i ++){
		if(p[i] == p[next[i - 1]])
			next[i] = next[i - 1] + 1;
		else{
			if(p[i] == p[0])
				next[i] = 1;
			else
				next[i] = 0;
		}
	}
}

int pattern_search(char *t, char *p){
	int len_t = strlen(t);
	int len_p = strlen(p);
	int *next = (int *)malloc(sizeof(int));
	prefix(p, next);
	
	int i = 0;
	int j = 0;
	while(i &lt; len_t){
		if(t[i] == p[j]){
			i ++;
			j ++;
		}
		if(j == len_p)
			return i - j;
		if(i &lt; len_t &amp;&amp; t[i] != p[j]){
			if(j != 0)
				j = next[j - 1];
			else
				i += 1;
		}
	}
	return -1;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Search  Algorithms]]></title>
        <id>https://raphael95.github.io/output/post/search-algorithms</id>
        <link href="https://raphael95.github.io/output/post/search-algorithms">
        </link>
        <updated>2019-05-30T07:33:49.000Z</updated>
        <summary type="html"><![CDATA[<p>üìùüìì record search algorithms</p>
<p>they are: linear search„ÄÅbinary search„ÄÅlinear selection„ÄÅTop K problem</p>
]]></summary>
        <content type="html"><![CDATA[<p>üìùüìì record search algorithms</p>
<p>they are: linear search„ÄÅbinary search„ÄÅlinear selection„ÄÅTop K problem</p>
<!-- more -->
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>Searching Algorithms are designed to check for an element or retrieve an element from any dta structure where it is stored. Based on the type of search operation, thesealgorithms are generally classified into two categories:</p>
<ol>
<li>Sequential Search: In this, the list or array is traversed sequentially and every element is checked. For example: Linear Search</li>
<li>Interval Search: These algorithms are specifically designed for searching in sorted data-structures. These type of searching algorithms are much more efficient than Linear Search as they repeatedly target the center of the search structure and divide the search space in half. For example: Binary Search.</li>
</ol>
<h2 id="linear-search"><strong>Linear Search</strong></h2>
<blockquote>
<p>time complexity: O(N)</p>
</blockquote>
<p>Linear search is uesed on a collections of items, it relies on the technique of traversing a list from start to end by exploring properties of all the elements that are found on the way.</p>
<p>For example, consider an array of integers of size N, you should find and print the position of all the elements with value X. Here, the linear search is based on the idea of matching each element from the begaining of the list to the end of the list with the integer X, and then printing the position of element if the condition is 'True'.</p>
<p>pseudocode in C:</p>
<pre><code>void find(int *a, int len){
	for(int i = 0; i &lt; len; i ++){
		if(a[i] == '5')
			print(&quot;%d \n&quot;, i);
	}
}
</code></pre>
<h2 id="binary-search"><strong>Binary Search</strong></h2>
<blockquote>
<p>time complexity: O(lgN)</p>
</blockquote>
<p>Binary search works only on a sorted set of elements. To use binary search on a collection, the collection must first be sorted.</p>
<p>When binary search is used to perform operations on a sorted set, the number of iterations can always be reduced on the basis of the value that is being searched.</p>
<p>pseudocode in C:</p>
<pre><code>int bin_search(int *a, int low, int high, const int x){
	int index = -1;
	int mid;
	if(low &lt;= high){
		mid = (low + high) / 2;
		if(a[mid] == x)
			return mid;
		if(a[mid] &lt; x)
			index = bin_search(a, mid + 1, high, x);
		else
			index = bin_search(a, low, mid - 1, x);
	}
	return index;
}
</code></pre>
<h2 id="linear-selection"><strong>Linear Selection</strong></h2>
<blockquote>
<p>time complexity: O(N)</p>
</blockquote>
<p>Now, we need to <strong><font color=red>find the k-th minimum/maximum item in an unsorted array,</font></strong> as we know, the selection problem can be solved in O(N * lgN) time, since we can sort the array using heap sort or merge sort and then simply index the k-th element in the output array. There are faster algorithms that the work can be done in expected linear time.</p>
<p>As in QuickSort algorithms, the idea is to partition the input array recursively. But unlike quicksort, which recursively process both sides of the partition, in linear selection, it only works on one side of the partition. This different shows up in the analysis: whereas quicksort has an expected running time of O(N * lg N), the expected time of linear selection is O(N).</p>
<p>pseudocode in C:</p>
<pre><code>int linear_selection(int *a, int low, int high, const in k){
	int count = 0;
	if(low == high)
		return a[low];
	int pivot = partition(a, low, high);
	count = oivot - low + 1;
	if(count &gt;= k)
		return linear_selection(a, low, count, k);
	else
		return linear_selection(a, count + 1, high, k - count);
</code></pre>
<h2 id="top-k-selection-problem"><strong>Top K Selection problem</strong></h2>
<p>Similar with linear selction problem, now, we need to <strong><font color=red>find the top k elements in an unsorted array,</font></strong> of course, you can write down such code as below:</p>
<pre><code>results = sorted(array, reverse=True)[: 10]
</code></pre>
<p>Anything involving a sort will usually take O(N * lgN) time, which will keep you waiting around for several seconds or even minutes when dealing with lots of items. An O(N * lgN) algorithm, for large N, simply cannot be run in realtime when users are waiting.</p>
<p>There are two ways to resolve the problem:</p>
<h3 id="1-solution-1-using-heap">1. solution 1: using heap</h3>
<blockquote>
<p>time complexity: O(N * lgK), space complecity: O(K)</p>
</blockquote>
<p>Luckily, finding the top k items can be done in O(N * lgK) time, which is much, much faster than O(N * lgN), using a heap, which is actually a priority queue. Assuming that we need to select top k maximum items in a list, as in heap sort, First, accordingly, we should build a minimum heap of size K to store the target items, and the top is always minimum item in the heap. Second, adding the rest of items in array recursively to heap if it is larger than top  element in the heap, Third, adjusting the heap and always place the minimum item to the top in the heap.</p>
<p>pseudocode in C:</p>
<pre><code>void adjust_heap(int *a, int root, int len){
	int left_child = 2 * root + 1;
	int right_child = 2 * root + 2;
	int max_child;
	if(left_child &gt;=len)
		return;
	else{
		if(right_child &gt;= len)
			max_child = left_child;
		else
			max_child = a[left_child] &gt; a[right_child]? left_child: right_child;
		if(a[root] &gt; a[max_child]){
			int tmp = a[root];
			a[root] = a[max_child];
			a[max_child] = tmp;
			adjust_heap(a, max_child, len);
		}
	}
}

void build_heap(int *a, int len){
	for(int i = len / 2 - 1; i &gt;=0; i --)
		adjust_heap(a, i, len);
}

void top_k(int *a, int len, const in k){
	int heap[k], i;
	for(i = 0; i &lt; k; i ++)
		heap[i] = a[i];
	build_heap(heap, k);
	for(i = k; i &lt; len; i ++){
		if(a[i] &gt; heap[0]){
			heap[0] = a[i];
			adjust(heap, 0, k); 
		}
	}
	
	// print the top k items;
	for(i = 0; i &lt; k; i ++)
		printf(&quot;%d &quot;, heap[i]);
}

</code></pre>
<h3 id="2-solution-2-using-linear-selection">2. solution 2: using linear selection</h3>
<blockquote>
<p>time complexity: O(N), space complexity: O(N)</p>
</blockquote>
<p>as we can see, the linear selection are faster than heap, however, it needs more space and may not wok well when space is limited.</p>
<p>we have learned about the linear selection algorithm in previous section, it uses partition function in QuickSort to get the pivot item and divide the array into two sublists, if the amount of left sublist equals to K, the left sublist will be the final Top K items, if amount is less than K, it will continue to find the rest (K - amount) items in right sublists, otherwise, it will continue to find the pivot that equals to K in left sublists.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sorting  Algorithms]]></title>
        <id>https://raphael95.github.io/output/post/sort-algorithms</id>
        <link href="https://raphael95.github.io/output/post/sort-algorithms">
        </link>
        <updated>2019-05-27T15:03:27.000Z</updated>
        <summary type="html"><![CDATA[<p>üìíüìùüìì record seven sort algorithms.</p>
<p>they are: bubble sort „ÄÅselection sort„ÄÅinsertion sort„ÄÅquick sort „ÄÅheap sort„ÄÅmerge sort„ÄÅcounting sort</p>
]]></summary>
        <content type="html"><![CDATA[<p>üìíüìùüìì record seven sort algorithms.</p>
<p>they are: bubble sort „ÄÅselection sort„ÄÅinsertion sort„ÄÅquick sort „ÄÅheap sort„ÄÅmerge sort„ÄÅcounting sort</p>
<!-- more -->
<h2 id="introduction">Introduction</h2>
<p>Some algorithms(<strong><a href="#selection">selection</a>, <a href="#bubble">bubble</a>, <a href="#heap">heap</a></strong>) work by moving elements to their final position, one at a time. You sort an array of size N, put 1 item in place and continue sorting and array of size N -1,</p>
<p>Some algorithms(<strong><a href="#insertion">insertion</a>, <a href="#quicksort">quicksort</a>, <a href="#counting">counting</a></strong>)put items to temporary place, closer to their final position, moving them closer to final position ,in each iteration.</p>
<p>Some algorithms(<strong><a href="#merge">merge</a></strong>) start with a 'sorted list ' of one element, and merge unsorted items into it, one at a time</p>
<h3 id="note">note</h3>
<ul>
<li>assume we are sorting a list or array of N elements</li>
<li>once sorted, smaller items are on the left, and larger items are on the right</li>
</ul>
<h3 id="span-idbubblebubble-sortspan"><strong><span id="bubble">Bubble Sort</span></strong></h3>
<blockquote>
<p>best: O(N), worst: O(N^2)</p>
</blockquote>
<p>¬†¬†starting on the left, compare adjacent items and keep 'bubbling' the the larger one to the right(it's in its final place), bubble sort the remaining N -1 items.</p>
<p>¬†¬†in each iteration, it will find the largest one in the rest of an array, and place it in the right.</p>
<p>pseudocode in C language:</p>
<pre><code>void bubble_sort(int *a, int len){
	int tmp;
	for(int i = 0; i &lt; len; i ++){
		for(int j = 0; j &lt; len - i - 1; i ++){
			if(a[j] &gt; a[j + 1]){
				tmp = a[j];
				a[j] = a[j + 1];
				a[j + 1] = tmp;
			}
		}
	}
}
</code></pre>
<h3 id="span-idselectionselection-sortspan"><strong><span id="selection">Selection Sort</span></strong></h3>
<blockquote>
<p>best/worst: O(N^2)</p>
</blockquote>
<p>¬†¬†scan all items and find the smallest. Swap it into the position as the first item. Repeat the selection sort on the remaining N - 1 items</p>
<p>¬†¬†it just like the bubble sort, the outer iteration from 0 to N - 1Ôºå the inner iteration is to find the minimun item, and always swap it with i.</p>
<pre><code>void selection_sort(int *a, int len){
	int min, index, tmp;
	for(int i = 0; i &lt; len; i ++){
		min= a[i];
		for(int j = i; j &lt; len; j ++){
			if(a[j] &lt; min){
				min = a[j];
				index = j;
			}
			tmp = a[i];
			a[i] = a[index];
			a[index] = tmp;
		}
	}
}
</code></pre>
<h3 id="span-idinsertioninsertion-sortspan"><strong><span id="insertion">Insertion Sort</span></strong></h3>
<blockquote>
<p>best: O(N)Ôºå worst: O(N^2)</p>
</blockquote>
<p>¬†¬†start with a sorted list of 1 element on the left, and N - 1 unsorted items on the right. Taking the first unsorted item (element #2) and insert it into the sorted list, moving elements as neccesary. We now have a sorted list of size 2, and N -2 unsorted items, repeat for all items.</p>
<pre><code>void insertion_sort(int *a, int len){
	int min;
	for(int i = 0; i &lt; len; i ++){
		int j = i;
		min = a[i];
		while(j &gt; 0 &amp;&amp; a[j - 1] &gt; min){
			a[j] = a[j - 1];
			j = j - 1;
		}
		a[j] = min;
	}
}
</code></pre>
<h3 id="span-idquicksortquick-sortspan"><strong><span id="quicksort">Quick Sort</span></strong></h3>
<blockquote>
<p>best: O(N * lgN), avg: O(N * lgN), worst: O(N^2)</p>
</blockquote>
<p>there are many versions of QuickSort, which is one of the most popular sorting methods due to its speed O(N * lgN) average, but O(N^2) worst cae, here's a few:</p>
<ul>
<li>pick a 'pivot' item</li>
<li>partition the other items by adding them to a 'less than pivot' sublist, and 'larger than pivot' sublist</li>
<li>the pivot goes between the two sublists</li>
<li>repeat the quicksort on the two sublists until you get to a sublist of size 1(which is sorted)</li>
</ul>
<p><strong>the most important in  QuickSort is partition function</strong></p>
<pre><code>int partition(int *a, int low, int high){
	int pivot = a[i];
	int i = low;
	int j = high;
	while(i &lt; j){
		while(j &gt; i &amp;&amp; a[j] &gt;= pivot)
			j --;
		if(j &gt; i)
			a[i] = a[j];
		while(i &lt; j &amp;&amp; a[i] &lt;=pivot)
			i ++;
		if(i &lt; j)
			a[j] = a[i];
	}
	a[i] = pivot;
	return i;
}

int quick_sort(int *a, int i, int j){
	if(i &lt; j){
		int pivot = partition(a, i, j);
		quick_sort(a, i, pivot - 1);
		quick_sort(a, pivot + 1, j);
</code></pre>
<p>however, the algorithms in the partition above has a defects, the time complexity can be O(N^2), we will elaborate how it happens now. <strong>If a bad pivot is chosen, you can imagine that the 'less than pivot' sublist is always empty, that means  we are only creating a sublist of one item smaller each time, which gives us O(N^2)behavior in the worst case. If you choose the first item, it may be the smallest item in the sorted list and give worst-case behavior. <font color=red>You can choose a random item, or median-of three(front,middle,rear)</font>.</strong></p>
<p>an improved partition function in QuickSort :</p>
<pre><code>void compare(int *a, int *b){
	if(*a &gt; *b){
		int tmp;
		tmp = *a;
		*a = *b;
		*b = tmp;
	}
}

void swap(int *a, int *b){
	int tmp = *a;
	*a = *b;
	*b = tmp;
}

void partition(int *a, int low, int high){
	int i = low;
	int j = high;
	int middle = (i + j) / 2;
	compare(&amp;a[i], &amp;a[middle]);
	compare(&amp;a[i], &amp;a[j]);
	compare(&amp;a[middle], &amp;a[j]);
	swap(&amp;a[i], &amp;a[middle]);
	int picot = a[i];
	while(i &lt; j){
		while(j &gt; i &amp;&amp; a[j] &gt;= picot)
			j --;
		if(j &gt; i)
			a[i] = a[j];
		while(i &lt; j &amp;&amp; a[i] &lt;=pivot)
			i ++;
		if(i &lt; j)
			a[j] = a[i];
		}
	a[i] = pivot;
	return i;
}
</code></pre>
<h3 id="span-idmergemerge-sortspan"><strong><span id="merge">Merge Sort</span></strong></h3>
<blockquote>
<p>best/avg/worst: O(N * lgN)</p>
</blockquote>
<p>Merge sort is a divid-and-conquer algorithm based on the idea of breaking down a list into several sublists until each sublists consists of a single element and merging those sublists to a sorted list.</p>
<ul>
<li>divide the unsorted lists into N sublists, each containing 1 element.</li>
<li>take adjacent pair of two singleton lists and merge them to from a list of 2 elements, N will now convert into N / 2 lists of size 2.</li>
<li>repeat the process till a single sorted lists of obtained.</li>
</ul>
<pre><code>void merge(int *a, int low, int middle, int high){
	int left_low = low;
	int left_high = middle;
	int right_low = middle + 1;
	int right_high = high;
	int k = 0;
	int *tmp = (int *)malloc(sizeof(int) * (high - low + 1));
	for(k &lt; high; left_low &lt; left_high &amp;&amp; right_low &lt; right_high; k ++){
		if(a[left_low] &lt; a[right_low])
			tmp[k] = a[left_low ++];
		else
			tmp[k] = a[right_low ++];
	}
	if(left_low &lt; left_high){
		for(int i = left_low; i &lt; left_high; i ++)
			tmp[k ++] = a[i];
	if(right_low &lt; right_high){
		for(int i = right_low; i &lt; right_low; i ++)
			tmp[k ++] = a[i];
	
	for(int i = 0; i &lt; high - low + 1; i ++)
		a[low + i] = tmp[i];
	
	free(tmp);
}

void merge_sort(int *a, int low, int high){
	if(low &lt; high){
		int middle = (low + high) / 2;
		merge_sort(a, low, middle);
		merge_sort(a, middle + 1, high);
		merge(a, low, middle, high);
	}
}
	
</code></pre>
<h3 id="span-idheapheap-sortspan"><strong><span id="heap">Heap Sort</span></strong></h3>
<blockquote>
<p>best/avg/worst: O(N * lgN)</p>
</blockquote>
<p>Heaps can be used in sorting an array, in max-heaps, maximum element will always be at the root, Heap sort uses this property of heap to sort the array. Adding all items into a heap, Pop the largest item from the heap and insert it at the end(final position), and repeat for all items.</p>
<p><strong>time complexity analysis</strong>:</p>
<p><font color=red>Creating the heap needs O(N * lgN).Poping items from heap is O(1), and adjust the heap after pop needs O(lgN), there are N pops, so there is another O(N * lgN) factor, which is O(N * lgN) overall.</font></p>
<p><font color=blue>Heap sort has O(N * lgN) behavior, even in the worst case, making it good for real-time applications.</font></p>
<pre><code>void adjust_heap(int *a, int root, int len){
	int left_child = 2 * root + 1;
	int right_child = 2 * root + 2;
	int max_child;
	if(left_child &gt;= size)
		return;
	else{
		if(righ_child &gt;= size)
			max_child = left_child;
		else
			max_child = a[left_child] &gt; a[right_child]? left_child, right_child;
		if(a[root] &lt; a[max_child]){
			int tmp = a[root];
			a[root] = a[max_child];
			a[max_child] = tmp;
			adjust_heap(a, max_child, len);
		}
	}
}

void build_heap(int *a, int len){
	for(int i = len / 2 - 1; i &gt;=0; i --)
		adjust_heap(a, i, len);
}

void heap_sort(int *a, int len){
	build_heap(a, len);
	for(int i = len - 1; i &gt;=0; i ++){
		int tmp = a[0];
		a[0] = a[i];
		a[i] = tmp;
		adjust_heap(a, 0, i);
	}
}
</code></pre>
<h3 id="span-idcountingcounting-sortspan"><strong><span id="counting">Counting Sort</span></strong></h3>
<blockquote>
<p>best/avg/worst: O(N)</p>
</blockquote>
<p>Assuming the data are integers, in a range of 0-K. Creating an array of size K to keep track of how many items appears(3 items with value 0, 4 items with value 1, etc.). Given this count, you can tell the position of an item ‚Äî‚Äî all the 1's must come after the 0's, of which these are 3. Therefore, the 1's start at item #4. Thus, we can scan the items and insert them into their proper position. <font color=red>In Counting Sort, the frequencies of distincts of the array to be sorted is counted and stored in an auxiliary array, by mapping its as value of the auxiliary array.</font></p>
<ul>
<li>Creating the auxiliary array is O(N)</li>
<li>Inserting items into their proper position needs O(N)</li>
</ul>
<pre><code>void counting_sort(int *a, int len){
	// find the maximum value
	int i;
	int max = 0;
	for(i = 0; i &lt; len; i ++){
		if(a[i] &gt; max)
			max = a[i];
	
	// initialize auxiliary array 
	int auxiliary[max];
	for(i=0; i &lt; max; i ++)
		auxiliary[i] = 0;
	
	for(i = 0; i &lt; len; i ++)
		auxiliary[a[i]] ++;
	
	int sorted_a[len];
	int j = 0;
	for(i = 0; i &lt;= max; i ++){
		counts = auxiliary[i];
		while(count --){
			sorted_a[j] = i;
			j ++;
		}
	}
	
	for(i = 0; i &lt; len; i ++){
		a[i] = auxiliary[i];
}
	
</code></pre>
]]></content>
    </entry>
</feed>